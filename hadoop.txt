Created a text file word.txt
2. Write a Python mapper code ( mapper.py)
3. Wrote a Python reducer ( reducer.py)
4. Add execute permission to these files
chmod +x mapper.py reducer.py
5. Upload  word.txt  to HDFS by creating a folder input
hdfs dfs -mkdir -p /user/cloudera/input
hdfs dfs -put word.txt /user/cloudera/input/
6. Run job using Hadoop Streaming
Hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
-input /user/cloudera/input/word.txt \
-output /user/cloudera/output \
-mapper “/user/bin/python mapper.py” \
-reducer “/user/bin/python reducer.py” \
-files mapper.py,reducer.py
7. View results from HDFS
hdfs dfs -cat /user/cloudera/output/part-00000



//new ver
mapper.py
#!/usr/bin/env python
import sys
# Read from standard input (Hadoop provides one line at a time)
for line in sys.stdin:
    line = line.strip()
    words = line.split()
    for word in words:
        print(f{word}\t)

reducer.py
#!/usr/bin/env python3
import sys
current_word = None
current_count = 0
for line in sys.stdin:
    word, count = line.strip().split('\t')
    count = int(count)
    if current_word == word:
       current_count += count
    else:
        if current_word:
           print(f"{current_word}\t{current_count}";)
        current_word = word
        current_count = count
# print the last word
if current_word:
   print(f"{current_word}\t{current_count}")

//old ver
mapper.py
#!/usr/bin/env python
import sys

for line in sys.stdin:
    line = line.strip()
    words = line.split()
    for word in words:
          print("{0}\t{1}".format(word, 1))


reducer.py
#!/usr/bin/env python
import sys

current_word = None
current_count = 0

for line in sys.stdin:
    line = line.strip()
    if not line:
        continue

    parts = line.split('\t', 1)
    if len(parts) != 2:
        continue

    word, count = parts
    try:
        count = int(count)
    except ValueError:
        continue

    if current_word == word:
        current_count += count
    else:
        if current_word:
            print("{0}\t{1}".format(current_word, current_count))
        current_word = word
        current_count = count

if current_word:
    print("{0}\t{1}".format(current_word, current_count))



which python
ls /usr/lib/hadoop-mapreduce/hadoop-streaming.jar

echo "hello world hello hadoop" | python mapper.py
echo -e "hello hadoop\nhello world" | python mapper.py | sort | python reducer.py

echo -e "Hello world\nHello Hadoop\nMapReduce is fun" > sample.txt
cat sample.txt | python mapper.py
cat sample.txt | python mapper.py | sort | python reducer.py
